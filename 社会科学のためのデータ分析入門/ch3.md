#第3章 測定
## 3.2 欠損データを扱う
### リストワイズ除去(listwise deletion)
任意のレコードにおいて、1変数でもデータ欠損(無回答)がある場合、当該レコードそのものを除去する手法。

## 3.4 標本調査

本読んでて、抽出法の定義とグループ分けで混乱したので、一旦下記サイトを見ながら整理。
https://bellcurve.jp/statistics/glossary/3538.html

### ランダム抽出かどうか別で抽出法を分類すると・・・

1. 確率抽出法(無作為抽出法)
	- 単純無作為抽出法(Simple Random Sampling:SRS)
	- 層化抽出法・層別抽出法
	- クラスター抽出法・集落抽出法
	- 多段抽出法
	- 系統抽出法
1. 非確率抽出法
	- 機縁法・縁故法
	- 応募法
	- インターセプト法
	- 割当法
		- 層化抽出法との違い
			- 層化抽出法は、あくまでも比率を揃えるだけで、どの手順も必ず無作為抽出する事が前提だが、割当法は無作為抽出ではない。必ず何らかのバイアスが存在する事を前提にしているのが割当法。
			- トルーマンの選挙におけるリサーチ会社の予想の大外れは、この割当法での調査に該当する。(最終的に調査員のバイアスが掛かってしまっていたので、層別抽出法ではなかった。)
	- 有意抽出法

#### 確率抽出法のいいところ
- 標本が、対象となる母集団を代表<sup>1</sup>するようになる
- 標本の特徴は、観察されるものもされないものも含め、母集団の特徴と平均的に等しくなる事が保証される。

<u>代表的(representative)</u>
- 抽出を何回も繰り返せば、抽出して得られた各標本の特徴は母集団のものと完全に一致すると言えないまでも、それら複数の標本全部は平均して母集団に一致する、という意味。
- 例えば、母集団に比べて少しばかり年齢の高い人達の標本が偶然得られたとしても、繰り返し標本を抽出していけば、年齢分布は母集団の分布に近くなる。

### 抽出の仕方別で抽出法を分類すると・・・
1. 復元抽出法(sampling with replacement)
	- インタビュー対象者となるユニットを選んだ後、再び標本抽出枠に戻すやり方
	- 何度も同じ人が対象者として選ばれる
1. 非復元抽出法(sampling without replacement)
	- 一旦インタビュー対象となるユニットを選んだら、それらのユニットを __標本抽出枠__(sampling frame:回答者となる可能性のある人全部が含まれるリスト) には戻さない

### 単純無作為抽出法(SRS)の難しさ
そもそも、母集団の全リストを用意する事が難しいので、完全にランダムに抽出する事が難しかったりする。
よく使われる抽出手法として、__無作為番号ダイアリング(Random Digit Dialing:RDD)__ があるが、これでも実際は「電話のある家庭」や「複数の電話を持っている人は選ばれやすい」などのバイアスが掛かってしまう。

### アフガニスタンのデータの抽出方法
- 多段クラスター抽出法
	- どうやら、多段抽出法＋クラスター抽出法を合わせて抽出してるらしい
		- 最初にまず関心のある5つの州を選んで、それぞれの州からさらに複数の地区を抽出し、更にそれぞれから複数の村を抽出し、村内の家の位置に基づいてランダムに家を選んである
- キッシュ・グリッド法(Kish grid)
	- 詳しい解説は見つからなかった・・・
	- けど、どうやら一つの世帯から、インタビューを受ける人をランダムに選び出すための手順(手法)っぽい

### 無回答とその他のバイアス発生要因
#### バイアスが発生する要因
- 全項目無回答(unit nonresponse)によるバイアス
	- サーベイ対象者として抽出したが、そもそも連絡が取れなかったり、回答をすべて拒否されたりする事を __全項目無回答(unit nonresponse)__ という
	- 全項目無回答の人と、そうでない人との間に体系的な差があった場合(＝ランダムに無回答者が決定されていないような状況(例：戦争関連の調査の時に、無回答の人の多くが戦況が酷い地域の人だった場合等))、バイアスが発生する
- 一部項目無回答(item nonresponse)によるバイアス
	- ある一定の質問項目について回答を拒否する事を __一部項目無回答__ という
	- 例えば、タリバンとISAFのいずれかから民間人が被害を受けたと思うかどうか？という設問では、被害が多発した州の無回答率が高く、それ以外の州は全員回答している。
		こういった偏りがある場合、導き出される推論も偏ってしまう
- 誤報告(misreporting)によるバイアス
	- これは例えば、単純にID番号付き解答用紙を本来の順番とはズレて記入してしまった、など
- 社会的望ましさバイアス(social desirability bias)
	- 自分が思う本当の回答とは裏腹に、社会的に望ましい答えを回答者が選んでしまう場合におきる偏り
	- 例：先進国の場合、「投票に行きましたか？」という設問に対して、本当は投票に行っていないけど行ったと答える傾向が知られている。これは、先進国では「投票を棄権する事は社会的に望ましくない」という考えが一般的であるためである。

#### 社会的望ましさバイアスを除くための手法
- アイテムカウント法(item count technique)、または リスト実験(list experiment)
	- 答えを直接答えさせるのではなく、「このリストの中にあなたが選ぶ選択肢の個数をお答えください」と聞く手法
	- この事で、回答者の答えにある程度の匿名性を与えられるので、社会的望ましさバイアスを除去する事が期待できる
- ランダム回答法(randomized reponse technique)
	- 回答してもらう際に、調査員にサイコロを見せないように転がしてもらい、以下のような回答をしてもらう
		- サイコロが「1」の場合：かならず「はい」と答える
		- サイコロが「2~5」の場合：質問に対して正直に「はい」か「いいえ」で答える
		- サイコロが「6」の場合：かならず「いいえ」と答える
	- 回答にランダム性を入れ込む事で、本人の意志として「はい」と「いいえ」のどちらを答えたのかをわからなくしつつ、ただサイコロの確率を用いて正直な回答の推定もできる。

##### アイテムカウント法とは
例をあげると・・・

- コントロールグループに対して
	- _質問：これから読み上げる団体や個人名のリストの中で、あなたが支持するものがいくつあるかを回答してください。_
	- _選択肢： カルザイ政権、国家連帯プログラム、地元農民_
- トリートメントグループに対して
	- _質問：これから読み上げる団体や個人名のリストの中で、あなたが支持するものがいくつあるかを回答してください。_
	- _選択肢： カルザイ政権、国家連帯プログラム、地元農民、__外国部隊___

上記例では、注目している回答が「外国部隊」。
それ以外の3つの選択肢については、コントロール群もトリートメント群も同じような回答傾向があると考えられるため、コントロール群から得られた数値データの平均は、トリートメント群における「ベース値」的に見て良い。
その上で、「外国部隊」が足されているので、トリートメント群とコントロール群の数値平均の差＝「外国部隊」を選んだ差、と考えても良いのだ！

##### アイテムカウント法の弱点
上述の例の場合、答える時に「0」や「4」と答えると、外国部隊を選んでいるのか居ないのかがわかってしまうため、「0」や「4」と答えたくても答えない人が出てきてしまう。
これらの問題は、それぞれ __床面効果(floor effect)__, __天井効果(ceiling effect)__ と呼ばれる。


## 3.5 政治的分極化を測定する
次の節のための前振りをしてるだけの節だよ。

- __空間投票モデル__
	- 経済的にリベラルか保守か、人種的にリベラルか保守か、を2軸に取った4象限モデル
	- ある議員の空間投票モデル上での位置と、とある法案のモデル上での位置と、現状の位置との距離を比較する事で、その議員がその法案に対して賛否どちらを選ぶのかは予想ができる

## 3.6 2変量関係の要約
### 3.6.2 相関
3.6.1で取り扱った、民主党と共和党の経済的イデオロギーが時とともに乖離していっている理由として、「所得の不平等が拡大していっているから」という事が言われている。
つまり、「_所得の不平等が拡大すればするほど、民主党と共和党のイデオロギー差が広まるような相関がある_」と言われている。
これが事実であるかどうかを検証してくぜ！

__ジニ係数__
- 所得の不平等を測定するための数値
	- 特に所得じゃなくてもいいんだけどね
$$
\text{ジニ係数} = \frac{\text{完全平等線とローレンツ曲線で挟まれた部分の面積}}{\text{完全平等線の下の面積}}
$$

__z得点__
- 任意の観察データ $x_i$ を、平均値 $\bar{x}$ と標準偏差 $S_x$ を使って標準化した値
	- $x_i$ の z得点 = $\frac{x_i - \bar{x}}{S_x}$
- 要は、データの基準点を平均値に平行移動(＝平均値を0としてプロットしなおす)して、広がり具合を標準偏差で補正してやってるイメージ
- なので、基本は単位が違うデータ同士でも、z得点に変換してあげれば比較ができる

__相関係数__
$$
\begin{aligned}
\text{相関係数} &= \frac{1}{n} \sum_{i=1}^{n}( x_i\text{のz得点} × y_i\text{のz得点}) \\
&= \frac{1}{n} \sum_{i=1}^{n}( \frac{x_i - \bar{x}}{S_x} × \frac{y_i - \bar{y}}{S_y}) \\
\end{aligned}
$$
(ｎの代わりに n-1 を使う事の方が多いが、標本サイズが充分に大きければどっちでもよい)

### 3.6.3 Q-Q プロット
#### PythonでQQプロット書く場合
下記のプラグインを入れておくと便利かも
https://github.com/matplotlib/mpl-probscale

#### Q-Q プロットとは
- quantile-quantile plot
- 分位数の散布図で、同じ分位数の値を2軸にプロットしていく

この本では、QQプロットの描き方の数学的説明がないので、Pythonでは描けなかった。
そもそもQQプロット自体をあまり見たことがないし、そもそも分位数と分位ポジションの2軸で、それぞれの値をプロットしても似たような事が見えるので、それでいいかな、って思った。

## 3.7 クラスター化
### 3.7.3 k平均法
#### k-means法とは
- 教師なし学習(unsupervised learning)の一種
- 各観察を、計測された数値データをもとにグルーピングする手法の一つ

#### 教師なし学習
- 目的
	- データ内の隠れた構造を発見すること
- 難点
	- 成功や失敗の明確な基準がないので、結果が正しいのかどうかは人の判断が必要。
		- 例えば k-meansでクラスタリングしたグルーピングが正しいのかどうかは、そのグルーピング結果から得られる知見が妥当であるかどうかを人間が改めて判断する必要がある


#### 手順
1. k個のクラスターの初期中心点をせたく
1. 各観察データから最も近い中心点を 1 で決められた中心点の中から選び出し、その中心点に属するクラスターとして割り当てる
1. 各クラスターごとにそれぞれの変数(軸)の平均値を算出し、その平均値の座標をあらたな「中心点」とする。
1. ステップ2に戻り、以降、2〜4ステップを延々と繰り返す。ただし、ステップ2でのクラスターへの割当の際に、どの観察点もクラスターが変化しなくなったら終了する。

#### 注意点
- 距離を算出する指標の単位が違ったり(例：身長と体重)、分布の中心点が大きく違ったり、分布の広がりが大きく違う場合は、それぞれのデータを __標準化__ しておく必要がある。
	- 変化幅が大きな指標と小さな指標をそのまま使って2次元距離でクラスタリングすると、大きな指標の方の影響を受けすぎるため、正しいクラスタリングができないため
	- 基本的には、 z得点化しておけばよい
